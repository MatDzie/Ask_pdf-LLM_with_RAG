# LLM-Chat-with-RAG

This repository will be used to create proof of concept for LLM chat with Retrieval Augmented Generation from files using embeddings in vector database.

# Tech stack
- **gpt-3.5-turbo-1106** - *LLM fine-tuned for chat purpouse*
- **embedding-model** - to be defined
- **chroma** - *vector data base to store embeddings*
- **pypdf** - for pdf parsing

# Setup
- pip install openai
- pip install pypdf
- set environment variable OPENAI_API_KEY="your-api-key-here"